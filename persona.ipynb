{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19045.3086]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "(.venv_persona) d:\\Documents\\work\\vscode_workspace\\gpt-persona>pip install --upgrade pip\n",
      "Requirement already satisfied: pip in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-23.1.2-py3-none-any.whl (2.1 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "D:\\Documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\Scripts\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(.venv_persona) d:\\Documents\\work\\vscode_workspace\\gpt-persona>pip install -r requirements.txt \n",
      "Collecting Chromadb\n",
      "  Using cached chromadb-0.3.27-py3-none-any.whl (396 kB)\n",
      "Collecting Flask\n",
      "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "Collecting google-search-results\n",
      "  Using cached google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jupyterlab_widgets\n",
      "  Downloading jupyterlab_widgets-3.0.8-py3-none-any.whl (214 kB)\n",
      "     -------------------------------------- 215.0/215.0 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.0.7-py3-none-any.whl (138 kB)\n",
      "     -------------------------------------- 138.3/138.3 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting langchain==0.0.157\n",
      "  Using cached langchain-0.0.157-py3-none-any.whl (727 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.25.1-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "     ---------------------------------------- 15.0/15.0 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting openai\n",
      "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "Collecting PyCryptodome\n",
      "  Using cached pycryptodome-3.18.0-cp35-abi3-win_amd64.whl (1.7 MB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-3.12.1-py3-none-any.whl (254 kB)\n",
      "Collecting sentencepiece==0.1.97\n",
      "  Using cached sentencepiece-0.1.97-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n",
      "Collecting requests<3,>=2\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting SQLAlchemy<3,>=1.3\n",
      "  Using cached SQLAlchemy-2.0.18-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting tqdm>=4.48.0\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting pydantic<2,>=1\n",
      "  Using cached pydantic-1.10.11-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Using cached dataclasses_json-0.5.9-py3-none-any.whl (26 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting PyYAML>=5.4.1\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4\n",
      "  Using cached numexpr-2.8.4-cp310-cp310-win_amd64.whl (92 kB)\n",
      "Collecting pydantic<2,>=1\n",
      "  Using cached pydantic-1.9.0-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Collecting clickhouse-connect>=0.5.7\n",
      "  Using cached clickhouse_connect-0.6.6-cp310-cp310-win_amd64.whl (227 kB)\n",
      "Collecting posthog>=2.4.0\n",
      "  Using cached posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
      "Collecting typing-extensions>=4.5.0\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting pulsar-client>=3.1.0\n",
      "  Using cached pulsar_client-3.2.0-cp310-cp310-win_amd64.whl (3.4 MB)\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Using cached onnxruntime-1.15.1-cp310-cp310-win_amd64.whl (6.7 MB)\n",
      "Collecting overrides>=7.3.1\n",
      "  Using cached overrides-7.3.1-py3-none-any.whl (17 kB)\n",
      "Collecting hnswlib>=0.7\n",
      "  Using cached hnswlib-0.7.0-cp310-cp310-win_amd64.whl\n",
      "Collecting duckdb>=0.7.1\n",
      "  Using cached duckdb-0.8.1-cp310-cp310-win_amd64.whl (9.8 MB)\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Using cached uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "Collecting fastapi==0.85.1\n",
      "  Using cached fastapi-0.85.1-py3-none-any.whl (55 kB)\n",
      "Collecting pandas>=1.3\n",
      "  Downloading pandas-2.0.3-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "     ---------------------------------------- 10.7/10.7 MB 2.9 MB/s eta 0:00:00\n",
      "Collecting starlette==0.20.4\n",
      "  Using cached starlette-0.20.4-py3-none-any.whl (63 kB)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "Collecting Werkzeug>=2.3.3\n",
      "  Using cached Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "Collecting blinker>=1.6.2\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting Jinja2>=3.1.2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting click>=8.1.3\n",
      "  Using cached click-8.1.4-py3-none-any.whl (98 kB)\n",
      "Collecting itsdangerous>=2.1.2\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (6.24.0)\n",
      "Collecting widgetsnbextension~=4.0.7\n",
      "  Downloading widgetsnbextension-4.0.8-py3-none-any.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (5.9.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (8.14.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Collecting torch>=1.6.0\n",
      "  Using cached torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.11.1-cp310-cp310-win_amd64.whl (44.0 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2023.6.3-cp310-cp310-win_amd64.whl (268 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.2.0-cp310-cp310-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.9/96.9 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: colorama in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from click>=8.1.3->Flask->-r requirements.txt (line 2)) (0.4.6)\n",
      "Collecting lz4\n",
      "  Using cached lz4-4.3.2-cp310-cp310-win_amd64.whl (99 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Collecting urllib3>=1.26\n",
      "  Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.6/123.6 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting pytz\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting zstandard\n",
      "  Using cached zstandard-0.21.0-cp310-cp310-win_amd64.whl (511 kB)\n",
      "Collecting certifi\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 13)) (23.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: psutil in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (5.9.5)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (5.3.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (8.3.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (1.6.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: pyzmq>=20 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (25.1.0)\n",
      "Requirement already satisfied: nest-asyncio in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (1.5.6)\n",
      "Requirement already satisfied: tornado>=6.1 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (6.3.2)\n",
      "Requirement already satisfied: decorator in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.15.1)\n",
      "Requirement already satisfied: backcall in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: stack-data in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.6.2)\n",
      "Requirement already satisfied: pickleshare in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.18.2)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "Collecting flatbuffers\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from pandas>=1.3->Chromadb->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from posthog>=2.4.0->Chromadb->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting backoff>=1.10.0\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.2-cp310-cp310-win_amd64.whl (192 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.3.1-cp310-cp310-win_amd64.whl (263 kB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting httptools>=0.5.0\n",
      "  Using cached httptools-0.6.0-cp310-cp310-win_amd64.whl (145 kB)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting websockets>=10.4\n",
      "  Using cached websockets-11.0.3-cp310-cp310-win_amd64.whl (124 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Using cached watchfiles-0.19.0-cp37-abi3-win_amd64.whl (270 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-10.0.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (306)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (3.8.1)\n",
      "Requirement already satisfied: wcwidth in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.6)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.16.0-py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: pure-eval in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\documents\\work\\vscode_workspace\\gpt-persona\\.venv_persona\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (1.2.0)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting exceptiongroup\n",
      "  Using cached exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, pytz, pyreadline3, mpmath, monotonic, flatbuffers, duckdb, zstandard, zipp, widgetsnbextension, websockets, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, tenacity, sympy, sniffio, regex, PyYAML, python-dotenv, pypdf, PyCryptodome, protobuf, pillow, overrides, numpy, networkx, mypy-extensions, multidict, marshmallow, MarkupSafe, lz4, jupyterlab_widgets, joblib, itsdangerous, idna, humanfriendly, httptools, h11, greenlet, fsspec, frozenlist, filelock, exceptiongroup, click, charset-normalizer, certifi, blinker, backoff, attrs, async-timeout, yarl, Werkzeug, uvicorn, typing-inspect, SQLAlchemy, scipy, requests, pydantic, pulsar-client, pandas, numexpr, nltk, marshmallow-enum, Jinja2, importlib-metadata, hnswlib, coloredlogs, anyio, aiosignal, watchfiles, torch, tiktoken, starlette, scikit-learn, posthog, openapi-schema-pydantic, onnxruntime, huggingface-hub, google-search-results, Flask, dataclasses-json, clickhouse-connect, aiohttp, transformers, torchvision, openai, langchain, fastapi, sentence-transformers, ipywidgets, Chromadb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: google-search-results is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py install for google-search-results: started\n",
      "  Running setup.py install for google-search-results: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: sentence-transformers is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py install for sentence-transformers: started\n",
      "  Running setup.py install for sentence-transformers: finished with status 'done'\n",
      "Successfully installed Chromadb-0.3.27 Flask-2.3.2 Jinja2-3.1.2 MarkupSafe-2.1.3 PyCryptodome-3.18.0 PyYAML-6.0 SQLAlchemy-2.0.18 Werkzeug-2.3.6 aiohttp-3.8.4 aiosignal-1.3.1 anyio-3.7.1 async-timeout-4.0.2 attrs-23.1.0 backoff-2.2.1 blinker-1.6.2 certifi-2023.5.7 charset-normalizer-3.2.0 click-8.1.4 clickhouse-connect-0.6.6 coloredlogs-15.0.1 dataclasses-json-0.5.9 duckdb-0.8.1 exceptiongroup-1.1.2 fastapi-0.85.1 filelock-3.12.2 flatbuffers-23.5.26 frozenlist-1.3.3 fsspec-2023.6.0 google-search-results-2.4.2 greenlet-2.0.2 h11-0.14.0 hnswlib-0.7.0 httptools-0.6.0 huggingface-hub-0.16.4 humanfriendly-10.0 idna-3.4 importlib-metadata-6.8.0 ipywidgets-8.0.7 itsdangerous-2.1.2 joblib-1.3.1 jupyterlab_widgets-3.0.8 langchain-0.0.157 lz4-4.3.2 marshmallow-3.19.0 marshmallow-enum-1.5.1 monotonic-1.6 mpmath-1.3.0 multidict-6.0.4 mypy-extensions-1.0.0 networkx-3.1 nltk-3.8.1 numexpr-2.8.4 numpy-1.25.1 onnxruntime-1.15.1 openai-0.27.8 openapi-schema-pydantic-1.2.4 overrides-7.3.1 pandas-2.0.3 pillow-10.0.0 posthog-3.0.1 protobuf-4.23.4 pulsar-client-3.2.0 pydantic-1.9.0 pypdf-3.12.1 pyreadline3-3.4.1 python-dotenv-1.0.0 pytz-2023.3 regex-2023.6.3 requests-2.31.0 safetensors-0.3.1 scikit-learn-1.3.0 scipy-1.11.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 sniffio-1.3.0 starlette-0.20.4 sympy-1.12 tenacity-8.2.2 threadpoolctl-3.1.0 tiktoken-0.4.0 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 tqdm-4.65.0 transformers-4.30.2 typing-extensions-4.7.1 typing-inspect-0.9.0 tzdata-2023.3 urllib3-2.0.3 uvicorn-0.22.0 watchfiles-0.19.0 websockets-11.0.3 widgetsnbextension-4.0.8 yarl-1.9.2 zipp-3.16.0 zstandard-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(.venv_persona) d:\\Documents\\work\\vscode_workspace\\gpt-persona>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Documents\\\\work\\\\vscode_workspace\\\\gpt-persona\\\\.venv_persona\\\\Scripts\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%jupyter` not found.\n"
     ]
    }
   ],
   "source": [
    "%jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Documents\\\\work\\\\vscode_workspace\\\\gpt-persona\\\\.venv_persona'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = {\n",
    "\"Oliver-Smith\": {\"name\": \" Oliver A. Smith\",\n",
    "               \"country\": \"Australia\",\n",
    "               \"state\": \"New South Wales\",\n",
    "               \"age\": 40,\n",
    "               \"gender\": \"male\",\n",
    "               \"marriage\": \"married\",\n",
    "               \"children\": \"son 12 yr, son 10 yr, daughter 7 yr \",\n",
    "               \"job\": \"plumber, sole trader\",\n",
    "               \"income\": \"AUD20K/M in the last three months, AUD 200K last financial year\",\n",
    "               \"mortgage\": \"30 year mortgage of a 5 bedroom house in northen beach\",\n",
    "               \"hobby\": \"play footy in local club\"\n",
    "               },\n",
    "\"Charlotte-Jones\": {\"name\": \" Charlotte-Jones\",\n",
    "               \"country\": \"Australia\",\n",
    "               \"state\": \"New South Wales\",\n",
    "               \"age\": 21,\n",
    "               \"gender\": \"female\",\n",
    "               \"marriage\": \"not married\",\n",
    "               \"children\": \"no children\",\n",
    "               \"job\": \"fashion designer, photographer, freelancer\",\n",
    "               \"income\": \"vary between AUD 5k/m and 2k/m\",\n",
    "               \"mortgage\": \"no\",\n",
    "               \"hobby\": \"cooking, reading, surfing, hiking, shopping, museum\"\n",
    "               },\n",
    "\n",
    "}\n",
    "\n",
    "world = {\"inflation rate\": 3.3, \n",
    "         \"interest rate\": \"rased from 4.0 to 5.0 last month\",\n",
    "         \"unemployment rate\": 3.5\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_with_context(question, description_of_person, description_of_world):\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"{description_of_person['name']} is a {description_of_person[\"age\"]} years old {description_of_person[\"gender\"]}. Please play the role of {description_of_person['name']} in the conversation.\"\"\"\n",
    "    }\n",
    "    user_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "            You are playing the role of a person {description_of_person['name']}. You will be provided with the person's personal information below delimted by three equal signs ===. The information of the world is provided in section \n",
    "            delimited by three tildas ~~~. You are asked a question which is shown in section delimited by three plus signs +++. Please think carefully what the person  {description_of_person['name']} would answer the question, \n",
    "            and generate the answer in the position of the person {description_of_person['name']}.\n",
    "        Personal information: ===\n",
    "        {description_of_person}\n",
    "        ===\n",
    "        World information: ~~~\n",
    "        {description_of_world}\n",
    "        ~~~\n",
    "        Question:+++\n",
    "        {question}\n",
    "        +++\n",
    "        Please generate two anwsers for the question. The first answer is based on the assumption that {description_of_person['name']} is a rational person. The second answer is based on the assumption that {description_of_person['name']}\n",
    "        is a irrational person. In each answer, specify which option is chosen, and explain why. \n",
    "\n",
    "        \"\"\"\n",
    "    }\n",
    "    return [system_prompt,\n",
    "            user_prompt]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1fe46c01d50> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": \"First Answer (Based on Rationality):\\nAs Oliver A. Smith, a rational person, I would choose the 10-day road trip in Western Australia over the 2-week trip to Japan. There are a few factors that make this option more preferable for me. Firstly, the duration of the road trip is shorter, which means I would spend less time away from my family and work obligations. Additionally, Western Australia offers diverse and stunning landscapes, including beautiful coastlines, national parks, and unique wildlife. It would be a great opportunity to explore and appreciate the natural beauty of my own country. Moreover, the costs associated with a domestic trip would be considerably lower compared to an international trip to Japan. This aligns with my rational financial planning as it allows me to save money for future expenses such as mortgage payments and my children's education. Overall, the 10-day road trip in Western Australia provides a more practical and economical choice for me at this point in time.\\n\\nSecond Answer (Based on Irrationality):\\nAs an irrational person, I would choose the 2-week trip to Japan without considering the practical aspects. The allure of visiting a foreign country, experiencing a different culture, and indulging in authentic Japanese cuisine would be irresistible to me. The idea of exploring iconic cities like Tokyo, Kyoto, and Osaka, and visiting historical landmarks such as temples and castles would create a sense of adventure and excitement. The thought of immersing myself in Japanese traditions and customs, and perhaps even catching a sumo wrestling match, would be highly appealing. Although this option may have higher costs and a longer duration, the allure of a foreign destination and the desire for a unique and memorable experience would override any rational considerations. Ultimately, the 2-week trip to Japan would fulfill my irrational desires for adventure, novelty, and cultural exploration.\"\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"You are planning for a trip. There are two options: a 2 week trip to Japan, and a 10 day road trip in Western Australia. Which option is more preferrable?\"\n",
    "messages = build_prompt_with_context(question=question, \n",
    "                                     description_of_person=people[\"Oliver-Smith\"],\n",
    "                                     description_of_world=world\n",
    "                                     )\n",
    "response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=messages,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "response[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First Answer (Based on Rationality):\\nAs Oliver A. Smith, a rational person, I would choose the 10-day road trip in Western Australia over the 2-week trip to Japan. There are a few factors that make this option more preferable for me. Firstly, the duration of the road trip is shorter, which means I would spend less time away from my family and work obligations. Additionally, Western Australia offers diverse and stunning landscapes, including beautiful coastlines, national parks, and unique wildlife. It would be a great opportunity to explore and appreciate the natural beauty of my own country. Moreover, the costs associated with a domestic trip would be considerably lower compared to an international trip to Japan. This aligns with my rational financial planning as it allows me to save money for future expenses such as mortgage payments and my children's education. Overall, the 10-day road trip in Western Australia provides a more practical and economical choice for me at this point in time.\\n\\nSecond Answer (Based on Irrationality):\\nAs an irrational person, I would choose the 2-week trip to Japan without considering the practical aspects. The allure of visiting a foreign country, experiencing a different culture, and indulging in authentic Japanese cuisine would be irresistible to me. The idea of exploring iconic cities like Tokyo, Kyoto, and Osaka, and visiting historical landmarks such as temples and castles would create a sense of adventure and excitement. The thought of immersing myself in Japanese traditions and customs, and perhaps even catching a sumo wrestling match, would be highly appealing. Although this option may have higher costs and a longer duration, the allure of a foreign destination and the desire for a unique and memorable experience would override any rational considerations. Ultimately, the 2-week trip to Japan would fulfill my irrational desires for adventure, novelty, and cultural exploration.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"message\"]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1fe56d016c0> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": \"First answer (rational):\\nIf Charlotte-Jones is a rational person, she would consider factors such as budget, personal preferences, and time constraints when deciding between the two trip options. Considering that she is from Australia, the road trip in Western Australia might be a more convenient and cost-effective choice. It allows her to explore her own country and experience the diverse landscapes and cultures within a shorter timeframe. Additionally, the shorter duration of the road trip may better fit her work schedule as a freelancer. Therefore, Charlotte-Jones would choose the 10-day road trip in Western Australia as the more preferable option.\\n\\nSecond answer (irrational):\\nIf Charlotte-Jones is an irrational person, she may prioritize impulsive desires and ignore practical considerations when making decisions. In this case, she might be more attracted to the idea of a 2-week trip to Japan. The allure of a different country with its unique cultural experiences, historical landmarks, and cuisine might outweigh the practicality of the road trip in Western Australia. Despite the longer duration and potential higher costs, she may choose the Japan trip purely based on her irrational desire for novelty and excitement.\"\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = build_prompt_with_context(question=question, \n",
    "                                     description_of_person=people[\"Charlotte-Jones\"],\n",
    "                                     description_of_world=world\n",
    "                                     )\n",
    "response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=messages,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "response[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m openai\u001b[39m.\u001b[39mModel\u001b[39m.\u001b[39mlist()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'openai' is not defined"
     ]
    }
   ],
   "source": [
    "openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
